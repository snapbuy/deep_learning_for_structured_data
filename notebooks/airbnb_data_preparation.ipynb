{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Airbnb Price Prediction - Data Preparation\n",
    "\n",
    "Use dataset published by Kaggle - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data - to train a simple deep learning model to predict prices for Airbnb properties.\n",
    "\n",
    "\n",
    "This notebook contains the common data loading and preparation steps:\n",
    "- load data from the input CSV\n",
    "- fix missing values\n",
    "- clean up anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common imports and variables\n",
    "Imports and variable definitions that are common to the entire notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.22.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: xlrd in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "# common imports\n",
    "import zipfile\n",
    "import time\n",
    "# import datetime, timedelta\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "from dateutil import relativedelta\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import math\n",
    "from subprocess import check_output\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is: c:\\Users\\snapb\\Documents\\GitHub\\deep_learning_for_structured_data\\notebooks\n",
      "path_to_yaml c:\\Users\\snapb\\Documents\\GitHub\\deep_learning_for_structured_data\\notebooks\\airbnb_data_preparation_config.yml\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "current_path = os.getcwd()\n",
    "print(\"current directory is: \"+current_path)\n",
    "\n",
    "path_to_yaml = os.path.join(current_path, 'airbnb_data_preparation_config.yml')\n",
    "print(\"path_to_yaml \"+path_to_yaml)\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common variables\n",
    "# control whether to load data from scratch from original source or from saved dataframe\n",
    "load_from_scratch = config['general']['load_from_scratch']\n",
    "# control whether to save dataframe with transformed data\n",
    "save_transformed_dataframe = config['general']['save_transformed_dataframe']\n",
    "# control whether rows containing erroneous values are removed from the saved dataset\n",
    "remove_bad_values = config['general']['remove_bad_values']\n",
    "# load default replacements for missing values\n",
    "text_default = config['general']['text_default']\n",
    "categorical_default = config['general']['categorical_default']\n",
    "time_default = config['general']['time_default']\n",
    "continuous_default = config['general']['continuous_default']\n",
    "# original CSV version of input (unprocessed) dataset\n",
    "input_csv = config['file_names']['input_csv']\n",
    "# saved pickled version of input dataset\n",
    "pickled_input_dataframe = config['file_names']['pickled_input_dataframe']\n",
    "# name of file to which prepared data set is saved as a pickled dataframe\n",
    "pickled_output_dataframe = config['file_names']['pickled_output_dataframe']\n",
    "# load lists of column categories\n",
    "collist = config['categorical']\n",
    "textcols = config['text']\n",
    "continuouscols = config['continuous']\n",
    "excludefromcolist = config['excluded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_from_scratch False\n",
      "save_transformed_dataframe True\n",
      "remove_bad_values True\n",
      "pickled_input_dataframe AB_NYC_2019_df.pkl\n",
      "pickled_output_dataframe AB_NYC_2019_remove_bad_values_jun21_2020.pkl\n",
      "defaults for text categorical time continuous are missing, missing, 2019-01-01, 0.0\n",
      "collist is:  ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
      "textcols is:  ['name', 'host_name']\n",
      "continuouscols is:  ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count']\n",
      "excludefromcolist is:  ['price', 'id', 'latitude', 'longitude', 'name', 'host_name', 'last_review']\n"
     ]
    }
   ],
   "source": [
    "print(\"load_from_scratch \"+str(load_from_scratch))\n",
    "print(\"save_transformed_dataframe \"+str(save_transformed_dataframe))\n",
    "print(\"remove_bad_values \"+str(remove_bad_values))\n",
    "print(\"pickled_input_dataframe \"+str(pickled_input_dataframe))\n",
    "print(\"pickled_output_dataframe \"+str(pickled_output_dataframe))\n",
    "print(\"defaults for text categorical time continuous are \"+text_default+\", \"+categorical_default+\", \"+str(time_default)+\", \"+str(continuous_default))\n",
    "print(\"collist is: \",str(collist))\n",
    "print(\"textcols is: \",str(textcols))\n",
    "print(\"continuouscols is: \",str(continuouscols))\n",
    "print(\"excludefromcolist is: \",str(excludefromcolist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "- ingest CVS into a Pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the directory for that this notebook is in and return the directory containing data files\n",
    "\n",
    "def get_path():\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
    "    return(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a path return the list of xls files in the directory\n",
    "def get_xls_list(path):\n",
    "    files = os.listdir(path)\n",
    "    files_xls = [f for f in files if f[-4:] == 'xlsx']\n",
    "    print(files)\n",
    "    print(files_xls)\n",
    "    return(files_xls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categories for input columns\n",
    "def define_feature_categories(df):\n",
    "    allcols = list(df)\n",
    "    print(\"all cols\",allcols)\n",
    "    textcols = ['name','host_name'] # \n",
    "    continuouscols = ['price','minimum_nights','number_of_reviews','reviews_per_month','calculated_host_listings_count','availability_365'] \n",
    "                      # columns to deal with as continuous values - no embeddings\n",
    "    timecols = ['last_review']\n",
    "    collist = ['neighbourhood_group','neighbourhood','room_type']\n",
    "    for col in continuouscols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    print('texcols: ',textcols)\n",
    "    print('continuouscols: ',continuouscols)\n",
    "    print('timecols: ',timecols)\n",
    "    print('collist: ',collist)\n",
    "    return(allcols,textcols,continuouscols,timecols,collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values according to the column category\n",
    "def fill_missing(dataset,allcols,textcols,continuouscols,timecols,collist):\n",
    "    logging.debug(\"before mv\")\n",
    "    for col in collist:\n",
    "        dataset[col].fillna(value=categorical_default, inplace=True)\n",
    "    for col in continuouscols:\n",
    "        dataset[col].fillna(value=continuous_default,inplace=True)\n",
    "    for col in timecols:\n",
    "        dataset[col].fillna(value=time_default,inplace=True)\n",
    "    for col in textcols:\n",
    "        dataset[col].fillna(value=text_default, inplace=True)\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataframe\n",
    "- load pickled dataframe\n",
    "- show info about the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data, either from original CSV file in data directory or from saved pickled dataframe\n",
    "def ingest_data(path):\n",
    "    if load_from_scratch:\n",
    "        unpickled_df = pd.read_csv(os.path.join(path,input_csv)) \n",
    "    else:\n",
    "        unpickled_df = pd.read_pickle(os.path.join(path,pickled_input_dataframe))\n",
    "        logging.debug(\"reloader done\")\n",
    "    return(unpickled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General cleanup\n",
    "- correct types for Route and Vehicle\n",
    "- fill missing values\n",
    "- create report-date-time index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset incorporated some anomalies in the 2019 data, including:\n",
    "# extraneous Incident ID in April 2019 tab\n",
    "# Gap and Delay columns in April and June 2019 tabs for what had otherwise been called Min Gap and Min Delay\n",
    "# this function cleans up these anomalies\n",
    "def fix_anomalous_columns(df):\n",
    "    # for rows where there is NaN in the Min Delay or Min Gap columns, copy over value from Delay or Gap\n",
    "    # df.Temp_Rating.fillna(df.Farheit, inplace=True)\n",
    "    df['Min Delay'].fillna(df['Delay'], inplace=True)\n",
    "    df['Min Gap'].fillna(df['Gap'], inplace=True)\n",
    "    # now that the useful values have been copied from Delay and Gap, remove them\n",
    "    del df['Delay']\n",
    "    del df['Gap']\n",
    "    # remove Incident ID column - it's extraneous\n",
    "    del df['Incident ID']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_time(date_time_value,time_value):\n",
    "    ''' given a datetime replace the time portion '''\n",
    "     \n",
    "    date_time_value = date_time_value.replace(hour=time_value.hour,minute=time_value.minute,second=time_value.minute)\n",
    "    return(date_time_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_cleanup(df):\n",
    "    # ensure Route and Vehicle are strings, not numeric\n",
    "    df['Route'] = df['Route'].astype(str)\n",
    "    df['Vehicle'] = df['Vehicle'].astype(str)\n",
    "    # remove extraneous characters left from Vehicle values being floats\n",
    "    df['Vehicle'] = df['Vehicle'].str[:-2]\n",
    "    # tactical definition of categories\n",
    "    allcols,textcols,continuouscols,timecols,collist = define_feature_categories(df)\n",
    "    # fill in missing values\n",
    "    df.isnull().sum(axis = 0)\n",
    "    df = fix_anomalous_columns(df)\n",
    "    df = fill_missing(df,allcols,textcols,continuouscols,timecols,collist)\n",
    "    # create new column combining date + time (needed for resampling) and make it the index\n",
    "    df['Report Date Time'] = df.apply(lambda x: replace_time(x['Report Date'], x['Time']), axis=1)\n",
    "    df.index = df['Report Date Time']\n",
    "    # return the updated dataframe along with the column category lists\n",
    "    return(df,allcols,textcols,continuouscols,timecols,collist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up selected columns\n",
    "Some values in the input dataset were entered \"free form\" when they should have been constricted to a pick list. Columns with this problem include:\n",
    "\n",
    "- Route\n",
    "- Vehicle\n",
    "- Direction\n",
    "- Location\n",
    "\n",
    "\n",
    "Each of these have a finite set of valid values. We have to fix the data in these columns where multiple tokens have been used to signify the same real-world entity (e.g. \"roncesvalles yard.\" and \"roncesvalles carhouse\", or where incorrect values have been entered (e.g. Direction that does not correspond with a compass point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_route (x):\n",
    "    if x in valid_routes:\n",
    "        return(x)\n",
    "    else:\n",
    "        return(\"bad route\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_cleanup(df):\n",
    "    print(\"Route count pre cleanup\",df['Route'].nunique())\n",
    "    # df['Route'].value_counts()\n",
    "    # replace bad route with common token\n",
    "    df['Route'] = df['Route'].apply(lambda x:check_route(x))\n",
    "    print(\"route count post cleanup\",df['Route'].nunique())\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vehicle (x):\n",
    "    if str.isdigit(x):\n",
    "        if int(x) in valid_vehicles:\n",
    "            return x\n",
    "        else:\n",
    "            return(\"bad vehicle\")\n",
    "    else:\n",
    "        return(\"bad vehicle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_cleanup(df):\n",
    "    print(\"Vehicle count pre cleanup\",df['Vehicle'].nunique())\n",
    "    df['Vehicle'] = df['Vehicle'].apply(lambda x:check_vehicle(x))\n",
    "    print(\"Vehicle count post cleanup\",df['Vehicle'].nunique())\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_direction (x):\n",
    "    if x in valid_directions:\n",
    "        return(x)\n",
    "    else:\n",
    "        return(\"bad direction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_cleanup(df):\n",
    "    print(\"Direction count pre cleanup\",df['Direction'].nunique())\n",
    "    df['Direction'] = df['Direction'].str.lower()\n",
    "    df['Direction'] = df['Direction'].str.replace('/','')\n",
    "    df['Direction'] = df['Direction'].replace({'eastbound':'e','westbound':'w','southbound':'s','northbound':'n'})\n",
    "    df['Direction'] = df['Direction'].replace('b','',regex=True)\n",
    "    df['Direction'] = df['Direction'].apply(lambda x:check_direction(x))\n",
    "    print(\"Direction count post cleanup\",df['Direction'].nunique())\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_conjunction(intersection):\n",
    "    intersection = re.sub(\" *& *\",\" and \",intersection)\n",
    "    intersection = re.sub(\" */ *\",\" and \",intersection)\n",
    "    return(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_location(intersection):\n",
    "    # for any string with the format \"* and *\" if the value before the and is alphabetically\n",
    "    # higher than the value after the and, swap the values\n",
    "    conj = \" and \"\n",
    "    alpha_ordered_intersection = intersection\n",
    "    if conj in intersection:\n",
    "        end_first_street = intersection.find(conj)\n",
    "        if (end_first_street > 0) and (len(intersection) > (end_first_street + len(conj))):\n",
    "            start_second_street = intersection.find(conj) + len(conj)\n",
    "            first_street = intersection[0:end_first_street]\n",
    "            second_street = intersection[start_second_street:]\n",
    "            alpha_ordered_intersection = min(first_street,second_street)+conj+max(first_street,second_street)\n",
    "    return(alpha_ordered_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_cleanup(df):\n",
    "    print(\"Location count pre cleanup\",df['Location'].nunique())\n",
    "    # make all location values lower case\n",
    "    df['Location'] = df['Location'].str.lower()\n",
    "    # make substitutions to eliminate obvious duplicate tokens\n",
    "    df['Location'] = df['Location'].replace({'broadviewstation':'broadview station',' at ':' and ',' stn':' station',' ave.':'','/':' and ','roncy':'roncesvalles','carhouse':'yard','yard.':'yard','st. clair':'st clair','ronc. ':'roncesvalles ','long branch':'longbranch','garage':'yard','barns':'yard',' & ':' and '}, regex=True)\n",
    "    # put intersection values into consistent order\n",
    "    df['Location'] = df['Location'].apply(lambda x:order_location(x))\n",
    "    print(\"Location count post cleanup\",df['Location'].nunique())\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with bad values\n",
    "def remove_bad(df):\n",
    "    df = df[df.Vehicle != 'bad vehicle']\n",
    "    df = df[df.Direction != 'bad direction']\n",
    "    df = df[df.Route != 'bad route']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master cell\n",
    "This cell contains calls to the other functions in this notebook to complete the data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path is  c:\\Users\\snapb\\Documents\\GitHub\\deep_learning_for_structured_data\\data\n",
      "all cols ['id', 'name', 'host_id', 'host_name', 'neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'last_review', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "texcols:  ['name', 'host_name']\n",
      "continuouscols:  ['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "timecols:  ['last_review']\n",
      "collist:  ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
      "Missing values in  id   0\n",
      "Distinct values  48895\n",
      "Missing values in  name   0\n",
      "Distinct values  47906\n",
      "Missing values in  host_id   0\n",
      "Distinct values  37457\n",
      "Missing values in  host_name   0\n",
      "Distinct values  11453\n",
      "Missing values in  neighbourhood_group   0\n",
      "Distinct values  5\n",
      "Missing values in  neighbourhood   0\n",
      "Distinct values  221\n",
      "Missing values in  latitude   0\n",
      "Distinct values  19048\n",
      "Missing values in  longitude   0\n",
      "Distinct values  14718\n",
      "Missing values in  room_type   0\n",
      "Distinct values  3\n",
      "Missing values in  price   0\n",
      "Distinct values  674\n",
      "Missing values in  minimum_nights   0\n",
      "Distinct values  109\n",
      "Missing values in  number_of_reviews   0\n",
      "Distinct values  394\n",
      "Missing values in  last_review   0\n",
      "Distinct values  1765\n",
      "Missing values in  reviews_per_month   0\n",
      "Distinct values  938\n",
      "Missing values in  calculated_host_listings_count   0\n",
      "Distinct values  47\n",
      "Missing values in  availability_365   0\n",
      "Distinct values  366\n",
      "number of records:  48895\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48895 entries, 0 to 48894\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              48895 non-null  int64  \n",
      " 1   name                            48895 non-null  object \n",
      " 2   host_id                         48895 non-null  int64  \n",
      " 3   host_name                       48895 non-null  object \n",
      " 4   neighbourhood_group             48895 non-null  object \n",
      " 5   neighbourhood                   48895 non-null  object \n",
      " 6   latitude                        48895 non-null  float64\n",
      " 7   longitude                       48895 non-null  float64\n",
      " 8   room_type                       48895 non-null  object \n",
      " 9   price                           48895 non-null  float64\n",
      " 10  minimum_nights                  48895 non-null  float64\n",
      " 11  number_of_reviews               48895 non-null  float64\n",
      " 12  last_review                     48895 non-null  object \n",
      " 13  reviews_per_month               48895 non-null  float64\n",
      " 14  calculated_host_listings_count  48895 non-null  float64\n",
      " 15  availability_365                48895 non-null  float64\n",
      "dtypes: float64(8), int64(2), object(6)\n",
      "memory usage: 6.0+ MB\n",
      "df.info() output None\n",
      "df.shape output (48895, 16)\n",
      "df.describe() output                  id       host_id      latitude     longitude         price  \\\n",
      "count  4.889500e+04  4.889500e+04  48895.000000  48895.000000  48895.000000   \n",
      "mean   1.901714e+07  6.762001e+07     40.728949    -73.952170    152.720687   \n",
      "std    1.098311e+07  7.861097e+07      0.054530      0.046157    240.154170   \n",
      "min    2.539000e+03  2.438000e+03     40.499790    -74.244420      0.000000   \n",
      "25%    9.471945e+06  7.822033e+06     40.690100    -73.983070     69.000000   \n",
      "50%    1.967728e+07  3.079382e+07     40.723070    -73.955680    106.000000   \n",
      "75%    2.915218e+07  1.074344e+08     40.763115    -73.936275    175.000000   \n",
      "max    3.648724e+07  2.743213e+08     40.913060    -73.712990  10000.000000   \n",
      "\n",
      "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
      "count    48895.000000       48895.000000       48895.000000   \n",
      "mean         7.029962          23.274466           1.090910   \n",
      "std         20.510550          44.550582           1.597283   \n",
      "min          1.000000           0.000000           0.000000   \n",
      "25%          1.000000           1.000000           0.040000   \n",
      "50%          3.000000           5.000000           0.370000   \n",
      "75%          5.000000          24.000000           1.580000   \n",
      "max       1250.000000         629.000000          58.500000   \n",
      "\n",
      "       calculated_host_listings_count  availability_365  \n",
      "count                    48895.000000      48895.000000  \n",
      "mean                         7.143982        112.781327  \n",
      "std                         32.952519        131.622289  \n",
      "min                          1.000000          0.000000  \n",
      "25%                          1.000000          0.000000  \n",
      "50%                          1.000000         45.000000  \n",
      "75%                          2.000000        227.000000  \n",
      "max                        327.000000        365.000000  \n",
      "df.types output id                                  int64\n",
      "name                               object\n",
      "host_id                             int64\n",
      "host_name                          object\n",
      "neighbourhood_group                object\n",
      "neighbourhood                      object\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "room_type                          object\n",
      "price                             float64\n",
      "minimum_nights                    float64\n",
      "number_of_reviews                 float64\n",
      "last_review                        object\n",
      "reviews_per_month                 float64\n",
      "calculated_host_listings_count    float64\n",
      "availability_365                  float64\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Route'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\snapb\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\snapb\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\snapb\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Route'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\snapb\\Documents\\GitHub\\deep_learning_for_structured_data\\notebooks\\airbnb_data_preparation.ipynb 셀 36\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdf.describe() output\u001b[39m\u001b[39m\"\u001b[39m,df\u001b[39m.\u001b[39mdescribe())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdf.types output\u001b[39m\u001b[39m\"\u001b[39m,df\u001b[39m.\u001b[39mdtypes)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=19'>20</a>\u001b[0m df,allcols,textcols,continuouscols,timecols,collist \u001b[39m=\u001b[39m general_cleanup(df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=20'>21</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=21'>22</a>\u001b[0m \u001b[39m# get record count by year\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\snapb\\Documents\\GitHub\\deep_learning_for_structured_data\\notebooks\\airbnb_data_preparation.ipynb 셀 36\u001b[0m in \u001b[0;36mgeneral_cleanup\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgeneral_cleanup\u001b[39m(df):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=1'>2</a>\u001b[0m     \u001b[39m# ensure Route and Vehicle are strings, not numeric\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=2'>3</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mRoute\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mRoute\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=3'>4</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mVehicle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mVehicle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/snapb/Documents/GitHub/deep_learning_for_structured_data/notebooks/airbnb_data_preparation.ipynb#ch0000035?line=4'>5</a>\u001b[0m     \u001b[39m# remove extraneous characters left from Vehicle values being floats\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\snapb\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\snapb\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Route'"
     ]
    }
   ],
   "source": [
    "# master cell to call the other functions\n",
    "# get the path for data files\n",
    "path = get_path()\n",
    "print(\"path is \",path)\n",
    "# load route direction and delay data datframes\n",
    "df = ingest_data(path)\n",
    "allcols,textcols,continuouscols,timecols,collist = define_feature_categories(df)\n",
    "# iterate through columns to get basic information\n",
    "for col in list(df):\n",
    "    print(\"Missing values in \",col,\" \",str(df[col].isna().sum()))\n",
    "    print(\"Distinct values \",str(df[col].nunique()))\n",
    "df = fill_missing(df,allcols,textcols,continuouscols,timecols,collist)\n",
    "df.head()\n",
    "\n",
    "print(\"number of records: \",len(df.index))\n",
    "print(\"df.info() output\",df.info())\n",
    "print(\"df.shape output\",df.shape)\n",
    "print(\"df.describe() output\",df.describe())\n",
    "print(\"df.types output\",df.dtypes)\n",
    "df,allcols,textcols,continuouscols,timecols,collist = general_cleanup(df)\n",
    "df.head()\n",
    "# get record count by year\n",
    "from collections import Counter\n",
    "df_year = pd.DatetimeIndex(df['Report Date Time']).year\n",
    "print(\"record count by year pre processing: \", str(Counter(df_year)))\n",
    "# check that the values for April 2019 are correct\n",
    "df[df['Report Date Time'].astype(str).str[:7]=='2019-04']\n",
    "# cleanup Route\n",
    "logging.debug(\"df.shape output pre route cleanup\",df.shape)\n",
    "df = route_cleanup(df) \n",
    "df = vehicle_cleanup(df)\n",
    "df = direction_cleanup(df)\n",
    "df = location_cleanup(df)\n",
    "logging.debug(\"df.shape output post location\",df.shape)\n",
    "print(\"Bad route count pre:\",df[df.Route == 'bad route'].shape[0])\n",
    "print(\"Bad direction count pre:\",df[df.Direction == 'bad direction'].shape[0])\n",
    "print(\"Bad vehicle count pre:\",df[df.Vehicle == 'bad vehicle'].shape[0])\n",
    "if remove_bad_values:\n",
    "    df = remove_bad(df)\n",
    "print(\"Bad route count:\",df[df.Route == 'bad route'].shape[0])\n",
    "print(\"Bad direction count:\",df[df.Direction == 'bad direction'].shape[0])\n",
    "print(\"Bad vehicle count:\",df[df.Vehicle == 'bad vehicle'].shape[0])\n",
    "# pickle the cleansed dataframe\n",
    "print(\"df.shape output post removal of bad records \",df.shape)\n",
    "\n",
    "if save_transformed_dataframe:\n",
    "    print(\"path is \",path)\n",
    "    file_name = os.path.join(path,pickled_output_dataframe)\n",
    "    print(\"file_name is \",file_name)\n",
    "    df.to_pickle(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room  149.0             1.0                9.0  2018-10-19   \n",
       "1  Entire home/apt  225.0             1.0               45.0  2019-05-21   \n",
       "2     Private room  150.0             3.0                0.0  2019-01-01   \n",
       "3  Entire home/apt   89.0             1.0              270.0  2019-07-05   \n",
       "4  Entire home/apt   80.0            10.0                9.0  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                             6.0             365.0  \n",
       "1               0.38                             2.0             355.0  \n",
       "2               0.00                             1.0             365.0  \n",
       "3               4.64                             1.0             194.0  \n",
       "4               0.10                             1.0               0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b1ec1654078b0271087af9da3713727b42f2c884c62c1556789ee7bbbdb80f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
